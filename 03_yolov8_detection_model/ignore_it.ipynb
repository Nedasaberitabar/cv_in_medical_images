{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24975,"status":"ok","timestamp":1701684154367,"user":{"displayName":"mehran d","userId":"05601808826632314029"},"user_tz":-210},"id":"tsmh-lwLDtQ8","outputId":"68e4c1dc-4bf1-47b2-b846-948c1b755c5d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"9ThnMN4zdZik"},"source":["# Tumor detection models : Yolov8"]},{"cell_type":"markdown","metadata":{"id":"b6cc37d2-b98d-40a4-a2b9-0ca3761cb12f"},"source":["# Table of Contents:\n","* [Explore and Visulaze Training Data](#chapter1)\n","* [Tumor Detection With Yolo8](#chapter5)\n","    * Implement Model\n","    * Training Model with Tumor Dataset\n","    * Model evaluation  \n","* [Conclusion  ](#chapter5)  "]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1701684154368,"user":{"displayName":"mehran d","userId":"05601808826632314029"},"user_tz":-210},"id":"YfN78TcxdGre"},"outputs":[],"source":["from IPython.display import clear_output"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":19386,"status":"ok","timestamp":1701684173749,"user":{"displayName":"mehran d","userId":"05601808826632314029"},"user_tz":-210},"id":"klvSaXzTdE8F"},"outputs":[],"source":["#!pip install numpy\n","#!pip install pandas\n","#!pip install matplotlib\n","#!pip install tensorflow\n","#!pip install seaborn\n","!pip install -U ultralytics\n","!pip install pybboxes\n","!pip install segmentation-models\n","clear_output()"]},{"cell_type":"markdown","metadata":{"id":"68cad4e9-cd88-4cd5-8728-50e82e991684"},"source":["# Imports  \u003ca class=\"anchor\" id=\"section1\"\u003e\u003c/a\u003e"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":5840,"status":"ok","timestamp":1701684179579,"user":{"displayName":"mehran d","userId":"05601808826632314029"},"user_tz":-210},"id":"d257b000-abd4-45d5-ad40-795673d3a64a"},"outputs":[],"source":["#import some necessary librairies\n","import os\n","import os.path\n","from pathlib import Path\n","import glob\n","import warnings\n","import shutil\n","import itertools\n","from warnings import filterwarnings\n","def ignore_warn(*args, **kwargs):\n","    pass\n","warnings.warn = ignore_warn #ignore all warning  message from librairies\n","\n","# linear algebra\n","import numpy as np\n","# data processing\n","import pandas as pd\n","\n","# plotting\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","#machine learning\n","import cv2\n","from PIL import Image\n","from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, roc_auc_score, roc_curve\n","from sklearn.model_selection import train_test_split\n","import tensorflow as tf\n","import keras\n","from keras.models import load_model"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":19,"status":"ok","timestamp":1701684179580,"user":{"displayName":"mehran d","userId":"05601808826632314029"},"user_tz":-210},"id":"b05e3d09-31b0-4049-9c87-48e15d28acc8"},"outputs":[],"source":["from tqdm import tqdm\n","from google.colab.patches import cv2_imshow"]},{"cell_type":"markdown","metadata":{"id":"S5z2CLQGMo__"},"source":["### Configs"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":666,"status":"ok","timestamp":1701684180231,"user":{"displayName":"mehran d","userId":"05601808826632314029"},"user_tz":-210},"id":"s3ehMvCSdKN7","outputId":"3f7d6754-4662-4b47-a1ff-8f2376167bae"},"outputs":[{"name":"stdout","output_type":"stream","text":["Segmentation Models: using `tf.keras` framework.\n"]}],"source":["pd.set_option('display.max_rows', 500)\n","pd.set_option('display.max_columns', 500)\n","pd.set_option('display.width', 1000)\n","#set seed to 42\n","import tensorflow as tf\n","tf.random.set_seed(42)\n","np.random.seed(42)\n","\n","%matplotlib inline\n","sns.set_theme()\n","\n","\n","os.environ['SM_FRAMEWORK'] = 'tf.keras'\n","tf.config.run_functions_eagerly(True)\n","import segmentation_models as sm"]},{"cell_type":"markdown","metadata":{"id":"b97e00c5-716d-4373-95e4-4fcfbc008004"},"source":["# CONSTANTS"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":50,"status":"ok","timestamp":1701684180231,"user":{"displayName":"mehran d","userId":"05601808826632314029"},"user_tz":-210},"id":"98865b84-ce6c-4d55-8655-e88c2b4846e4"},"outputs":[],"source":["PROJECT_NAME = \"Yolov8 Tumor Detection\" #just for project title\n","RANDOM_SEED = 42\n","IMAGE_SIZE = (640,640)\n","SAMPLE_NUMBER = 0\n","# Batch size for training\n","BATCH_SIZE = 16\n","# Training Epochs\n","EPOCHS = 60\n","CHANNEL= 3\n","USE_PRETRAINED = False\n","# Filters for pretrained models\n","#FILTER_LIST = [ 32,64,128 ]"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":48,"status":"ok","timestamp":1701684180232,"user":{"displayName":"mehran d","userId":"05601808826632314029"},"user_tz":-210},"id":"Hqlq1OO843Cl"},"outputs":[],"source":["MAIN_PROJECT_PATH=  \"/content/drive/MyDrive/projects/my_final_project/03_yolo_detection_model\"\n","PRETRAINED_MODEL_PATH =    MAIN_PROJECT_PATH+'/runs/detect/yolov8n_fintuend/weights/best.pt'"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":46,"status":"ok","timestamp":1701684180232,"user":{"displayName":"mehran d","userId":"05601808826632314029"},"user_tz":-210},"id":"Lv98F8sEX-Cb"},"outputs":[],"source":["YOLO_DATASET_PATH = \"/content/drive/MyDrive/projects/my_final_project/datasets/yolo_dataset/\"\n","val_images_dir=YOLO_DATASET_PATH+\"valid/images\"\n","val_labels_dir=YOLO_DATASET_PATH+\"valid/labels\""]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":43,"status":"ok","timestamp":1701684180232,"user":{"displayName":"mehran d","userId":"05601808826632314029"},"user_tz":-210},"id":"dITfK8P4X_IG"},"outputs":[],"source":["yaml_file= f\"\"\"path: {YOLO_DATASET_PATH}\n","train: 'train/images'\n","val:   'valid/images'\n","test: 'test/images'\n","\n","nc: 3\n","names: ['Glioma', 'Meningioma', 'Pituitary']\n","\"\"\"\n","with open(\"dataset.yaml\",\"w\") as f :\n","  f.write(yaml_file)"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":140},"executionInfo":{"elapsed":42,"status":"error","timestamp":1701684180233,"user":{"displayName":"mehran d","userId":"05601808826632314029"},"user_tz":-210},"id":"kuhJNJMzP8Pz","outputId":"fdec9938-13bf-4eb1-a7f5-24e410bb5a98"},"outputs":[{"ename":"SyntaxError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;36m  File \u001b[0;32m\"\u003cipython-input-11-57fff80084d0\u003e\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    path_to_logs =MAIN_PROJECT_PATH+'/runs/detect/yolov8n_fintuend\u001b[0m\n\u001b[0m                                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 5)\n"]}],"source":["if USE_PRETRAINED:\n","  %load_ext tensorboard\n","  %tensorboard --logdir runs/detect/yolov8n_finetuned\n","else:\n","  path_to_logs =MAIN_PROJECT_PATH+'/runs/detect/yolov8n_fintuend'\n","  %load_ext tensorboard\n","  %tensorboard --logdir path_to_logs"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"executionInfo":{"elapsed":34,"status":"aborted","timestamp":1701684180233,"user":{"displayName":"mehran d","userId":"05601808826632314029"},"user_tz":-210},"id":"NHKhWoIKX_Ke"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n","  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n","  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n","  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n"," 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n"," 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 22        [15, 18, 21]  1    897664  ultralytics.nn.modules.head.Detect           [80, [64, 128, 256]]          \n","YOLOv8n summary: 225 layers, 3157200 parameters, 3157184 gradients, 8.9 GFLOPs\n","\n","Ultralytics YOLOv8.0.222 🚀 Python-3.10.12 torch-2.1.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.yaml, data=dataset.yaml, epochs=60, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=yolov8n_finetuned, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/yolov8n_finetuned\n","Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 755k/755k [00:00\u003c00:00, 38.3MB/s]"]},{"name":"stdout","output_type":"stream","text":["Overriding model.yaml nc=80 with nc=3\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n","  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n","  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n","  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n"," 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n"," 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 22        [15, 18, 21]  1    751897  ultralytics.nn.modules.head.Detect           [3, [64, 128, 256]]           \n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["YOLOv8n summary: 225 layers, 3011433 parameters, 3011417 gradients, 8.2 GFLOPs\n","\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/yolov8n_finetuned', view at http://localhost:6006/\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n","Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt to 'yolov8n.pt'...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 6.23M/6.23M [00:00\u003c00:00, 193MB/s]\n"]},{"name":"stdout","output_type":"stream","text":["WARNING ⚠️ NMS time limit 0.550s exceeded\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"]}],"source":["from ultralytics import YOLO\n","\n","if not USE_PRETRAINED:\n","    model = YOLO('yolov8n.yaml')\n","    # Training.\n","    results = model.train(\n","      data='dataset.yaml',\n","      imgsz=640,\n","      epochs=EPOCHS,\n","      batch=BATCH_SIZE,\n","      name='yolov8n_finetuned')\n","else:\n","   model=YOLO(PRETRAINED_MODEL_PATH)"]},{"cell_type":"markdown","metadata":{"id":"YB9L-g8yuVK4"},"source":["# Evaluation model on Test Data"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":34,"status":"aborted","timestamp":1701684180233,"user":{"displayName":"mehran d","userId":"05601808826632314029"},"user_tz":-210},"id":"my-IDTTbuZHe"},"outputs":[],"source":["sample_1=  YOLO_DATASET_PATH+\"valid/images/2020_png.rf.61a66efb749331bdac56346e44ca5f50.jpg\"\n","sample_2=  YOLO_DATASET_PATH+\"valid/images/2079_png.rf.31eca1b5a5f58ac9b8c9c5095a8b4514.jpg\"\n","sample_3=  YOLO_DATASET_PATH+\"valid/images/2095_png.rf.4bc0cde0532e58080addd09486fc4153.jpg\"\n","sample_5=  YOLO_DATASET_PATH+\"valid/images/218_png.rf.fb1d030bab9d7fc8aea2d7e19db7cb3c.jpg\"\n","sample_6=  YOLO_DATASET_PATH+\"valid/images/855_png.rf.e3ad6e7a65abb542599af8ef0bbb281c.jpg\""]},{"cell_type":"markdown","metadata":{"id":"wFkExPe5NXNt"},"source":["### Visulize Trained Models Prediction on Validation images"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":35,"status":"aborted","timestamp":1701684180234,"user":{"displayName":"mehran d","userId":"05601808826632314029"},"user_tz":-210},"id":"KgM_fBPX_2yr"},"outputs":[],"source":["def get_image_file_annotation(image_item,dataset_path,file_name):\n","    import pybboxes as pbx\n","\n","    points_scaled=None\n","    full_p = os.path.join(dataset_path.replace(\"images\",\"labels\"),file_name[:-3]+\"txt\")\n","\n","    classes = []\n","    with open(full_p,\"r\") as f:\n","      #(x, y, w, h )\n","      classes =f.read().split(\"\\n\")\n","      for cls in classes:\n","          yolo_bbox1 =   list(map(float, cls.split(\" \")))\n","          H, W = image_item.shape[:2]\n","          yolo_bbox1 =yolo_bbox1[1:]\n","          box_voc=pbx.convert_bbox(yolo_bbox1, from_type=\"yolo\", to_type=\"voc\", image_size=(W, H))\n","          fname =file_name\n","          dimensions = image_item.shape\n","          output_mask=cv2.rectangle(image_item,\n","                                      (box_voc[0], box_voc[1]),\n","                                      (box_voc[2], box_voc[3]),\n","                                      (0, 255, 0), 2)\n","\n","    return output_mask\n"]},{"cell_type":"markdown","metadata":{"id":"j37EWKUIRQg4"},"source":["### Samples real bbox vs prediction"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":34,"status":"aborted","timestamp":1701684180234,"user":{"displayName":"mehran d","userId":"05601808826632314029"},"user_tz":-210},"id":"KQLtFse-_7H0"},"outputs":[],"source":["img_sample_1 = cv2.imread(sample_1)\n","img_sample_1=  cv2.resize(img_sample_1,(640,640))\n","cv2_imshow(get_image_file_annotation(img_sample_1,val_images_dir,sample_1.split(\"/\")[-1]))"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":34,"status":"aborted","timestamp":1701684180234,"user":{"displayName":"mehran d","userId":"05601808826632314029"},"user_tz":-210},"id":"KUfL6urfYPwl"},"outputs":[],"source":["results1 = model(sample_1)  # results list\n","# Show the results\n","plt.grid(False)\n","for r in results1:\n","    im_array = r.plot()  # plot a BGR numpy array of predictions\n","    im = Image.fromarray(im_array[..., ::-1])  # RGB PIL image\n","    plt.imshow(im) # show image\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":34,"status":"aborted","timestamp":1701684180234,"user":{"displayName":"mehran d","userId":"05601808826632314029"},"user_tz":-210},"id":"dHbJqoVOBIPu"},"outputs":[],"source":["img_sample_2 = cv2.imread(sample_2)\n","img_sample_2=  cv2.resize(img_sample_2,(416,416))\n","cv2_imshow(get_image_file_annotation(img_sample_2,val_images_dir,sample_2.split(\"/\")[-1]))"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":34,"status":"aborted","timestamp":1701684180234,"user":{"displayName":"mehran d","userId":"05601808826632314029"},"user_tz":-210},"id":"gMBkLxpAYR6U"},"outputs":[],"source":["results1 = model(sample_2)  # results list\n","# Show the results\n","plt.grid(False)\n","for r in results1:\n","    im_array = r.plot()  # plot a BGR numpy array of predictions\n","    im = Image.fromarray(im_array[..., ::-1])  # RGB PIL image\n","    plt.imshow(im) # show image\n"]},{"cell_type":"markdown","metadata":{"id":"8ZZEX7vsOw_v"},"source":["### Model Evaluations:"]},{"cell_type":"markdown","metadata":{"id":"cD-hKY6cO7v1"},"source":["##### Model Confusion Matrix"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":33,"status":"aborted","timestamp":1701684180235,"user":{"displayName":"mehran d","userId":"05601808826632314029"},"user_tz":-210},"id":"EzfoBOMNPkk_"},"outputs":[],"source":["PLOTS_PATH = \"\"\n","if USE_PRETRAINED:\n","  PLOTS_PATH=MAIN_PROJECT_PATH+'/runs/detect/yolov8n_finetuned/'\n","else:\n","  PLOTS_PATH= '/runs/detect/yolov8n_finetuned/'"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":32,"status":"aborted","timestamp":1701684180235,"user":{"displayName":"mehran d","userId":"05601808826632314029"},"user_tz":-210},"id":"LQYLm1NsO1xz"},"outputs":[],"source":["plt.grid(False)\n","plt.imshow(plt.imread(PLOTS_PATH+\"confusion_matrix.png\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":32,"status":"aborted","timestamp":1701684180235,"user":{"displayName":"mehran d","userId":"05601808826632314029"},"user_tz":-210},"id":"xR3AnBvIPxuy"},"outputs":[],"source":["plt.grid(False)\n","\n","plt.imshow(plt.imread(PLOTS_PATH+\"confusion_matrix_normalized.png\"))"]},{"cell_type":"markdown","metadata":{"id":"a1FDyml-PBN9"},"source":["##### Model Percesion"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":32,"status":"aborted","timestamp":1701684180235,"user":{"displayName":"mehran d","userId":"05601808826632314029"},"user_tz":-210},"id":"NJ8ONBC-O2dd"},"outputs":[],"source":["plt.grid(False)\n","plt.imshow(plt.imread(PLOTS_PATH+\"P_curve.png\"))"]},{"cell_type":"markdown","metadata":{"id":"Xnrrk3TDPJyv"},"source":["##### Model Recal"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":32,"status":"aborted","timestamp":1701684180235,"user":{"displayName":"mehran d","userId":"05601808826632314029"},"user_tz":-210},"id":"I9uxrg4HO2qf"},"outputs":[],"source":["plt.grid(False)\n","plt.imshow(plt.imread(PLOTS_PATH+\"R_curve.png\"))"]},{"cell_type":"markdown","metadata":{"id":"gorTeW9BPOel"},"source":["##### Model F1 Score"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":32,"status":"aborted","timestamp":1701684180236,"user":{"displayName":"mehran d","userId":"05601808826632314029"},"user_tz":-210},"id":"vbDE_mpTO21O"},"outputs":[],"source":["plt.grid(False)\n","plt.imshow(plt.imread(PLOTS_PATH+\"F1_curve.png\"))"]},{"cell_type":"markdown","metadata":{"id":"EebUdAFjQbYO"},"source":["##### Model Results"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":32,"status":"aborted","timestamp":1701684180236,"user":{"displayName":"mehran d","userId":"05601808826632314029"},"user_tz":-210},"id":"RGRYRc2GQak-"},"outputs":[],"source":["plt.figure(figsize=(16,10))\n","plt.imshow(plt.imread(PLOTS_PATH+\"results.png\"))"]},{"cell_type":"markdown","metadata":{"id":"vU6c7fT8whtZ"},"source":["### Evaluation with some Test Data on internet (out of our validation data)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":32,"status":"aborted","timestamp":1701684180236,"user":{"displayName":"mehran d","userId":"05601808826632314029"},"user_tz":-210},"id":"V8zp--hBWCVc"},"outputs":[],"source":["# Run inference on 'bus.jpg'\n","results = model(\"1561fig01.jpeg\")  # results list\n","plt.grid(False)\n","# Show the results\n","for r in results:\n","    im_array = r.plot()  # plot a BGR numpy array of predictions\n","    im = Image.fromarray(im_array[..., ::-1])  # RGB PIL image\n","    plt.imshow(im) # show image\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":32,"status":"aborted","timestamp":1701684180236,"user":{"displayName":"mehran d","userId":"05601808826632314029"},"user_tz":-210},"id":"K7n2k_aTwd7J"},"outputs":[],"source":["# Run inference on 'bus.jpg'\n","results = model(\"big_5b252c1a32b7d.jpg\")  # results list\n","plt.grid(False)\n","# Show the results\n","for r in results:\n","    im_array = r.plot()  # plot a BGR numpy array of predictions\n","    im = Image.fromarray(im_array[..., ::-1])  # RGB PIL image\n","    plt.imshow(im) # show image"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":32,"status":"aborted","timestamp":1701684180236,"user":{"displayName":"mehran d","userId":"05601808826632314029"},"user_tz":-210},"id":"8vVxk6EK1NvY"},"outputs":[],"source":["import torch\n","from ultralytics.utils.plot_results import plot_results  # You may need to adjust the import based on YOLOv8's repository structure\n","from ultralytics.utils.metrics import ap_per_class\n","from ultralytics.utils.loss import ComputeLoss\n","from models.experimental import attempt_load\n","\n","def evaluate_model(weights_path, data_cfg, batch_size, img_size, conf_thres, iou_thres, task='val'):\n","    # Load model\n","    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","    model = attempt_load(weights_path, map_location=device).half()  # Load to FP16 if using GPU\n","    model.eval()\n","\n","    # Configure dataset\n","    data_dict = parse_data_cfg(data_cfg)\n","    dataset = LoadImagesAndLabels(data_dict[task], batch_size, img_size, augment=False)\n","\n","    dataloader = torch.utils.data.DataLoader(dataset,\n","                                             batch_size=batch_size,\n","                                             num_workers=min([os.cpu_count(), batch_size if batch_size \u003e 1 else 0, 8]),\n","                                             pin_memory=True,\n","                                             collate_fn=dataset.collate_fn)\n","\n","    # Initialize metrics\n","    seen = 0\n","    names = model.module.names if hasattr(model, 'module') else model.names\n","    s = ('%20s' + '%10s' * 7) % ('Class', 'Images', 'Targets', 'P', 'R', 'mAP@.5', 'mAP@.5:.95')\n","    p, r, f1, mp, mr, map50, map = [0] * 7\n","    loss = torch.zeros(3)\n","    jdict, stats, ap, ap_class = [], [], [], []\n","    compute_loss = ComputeLoss(model)\n","\n","    # Run through data\n","    for batch_i, (img, targets, paths, shapes) in enumerate(dataloader):\n","        img = img.to(device).float() / 255.0\n","        img = img.to(device).half() if device == 'cuda' else img.to(device)\n","        targets = targets.to(device)\n","        nb, _, height, width = img.shape  # Batch size, channels, height, width\n","\n","        # Forward pass\n","        with torch.no_grad():\n","            pred = model(img)[0]\n","\n","        # Compute loss\n","        loss += compute_loss(pred, targets, model)[1][:3]  # Box, obj, class losses\n","\n","        # Compute statistics\n","        stats += get_batch_statistics(pred, targets, iou_threshold=iou_thres)\n","\n","        # Log progress\n","        seen += nb\n","\n","    # Compute mean metrics\n","    stats = [np.concatenate(x, 0) for x in list(zip(*stats))]  # to numpy\n","    if len(stats):\n","        p, r, ap, f1, ap_class = ap_per_class(*stats)\n","        mp, mr, map50, map = p.mean(), r.mean(), ap.mean(0), ap[:, 1].mean()\n","\n","    # Print results\n","    pf = '%20s' + '%10.3g' * 7  # Print format\n","    print(pf % ('all', seen, 0, mp, mr, map50, map))\n","\n","    # Return detailed results\n","    return (mp, mr, map50, map), model\n","\n","# Place your paths and configuration here\n","weights = \"/content/drive/MyDrive/projects/my_final_project/03_yolov8_detection_model/runs/detect/yolov8n_finetuned/weights/best.pt\"\n","cfg = 'dataset.yaml'\n","evaluate_model(weights, cfg, batch_size=16, img_size=640, conf_thres=0.001, iou_thres=0.65)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":32,"status":"aborted","timestamp":1701684180237,"user":{"displayName":"mehran d","userId":"05601808826632314029"},"user_tz":-210},"id":"xuP4Z3xC211A"},"outputs":[],"source":["results = model.val()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":32,"status":"aborted","timestamp":1701684180237,"user":{"displayName":"mehran d","userId":"05601808826632314029"},"user_tz":-210},"id":"8c_xpv5U3DcK"},"outputs":[],"source":["class_names = list(results.names)\n","for class_name in class_names:\n","  class_index = class_names.index(class_name)\n","  try:\n","    precision = results.box.class_result(class_index)[0]\n","    recall = results.box.class_result(class_index)[1]\n","    f1_score = results.box.class_result(class_index)[2]\n","    print(f\"Class: {class_name}\")\n","    print(f\"Precision: {precision}\")\n","    print(f\"Recall: {recall}\")\n","    print(f\"F1-score: {f1_score}\")\n","  except Exception as e:\n","    continue"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":32,"status":"aborted","timestamp":1701684180237,"user":{"displayName":"mehran d","userId":"05601808826632314029"},"user_tz":-210},"id":"Mimu8AHK69wD"},"outputs":[],"source":["import pandas as pd\n","\n","class_names = list(results.names)\n","metrics_dict = {}\n","for class_name in class_names:\n","  try:\n","    class_index = class_names.index(class_name)\n","    precision = results.box.class_result(class_index)[0]\n","    recall = results.box.class_result(class_index)[1]\n","    f1_score = results.box.class_result(class_index)[2]\n","    metrics_dict[class_name] = {'Precision': precision, 'Recall': recall, 'F1-score': f1_score}\n","  except Exception as e:\n","    continue\n","df = pd.DataFrame(metrics_dict)\n","print(df)"]}],"metadata":{"accelerator":"GPU","colab":{"name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"}},"nbformat":4,"nbformat_minor":5}